{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bdd2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "a3main.py\n",
    "\n",
    "UNSW ZZEN9444 Neural Networks and Deep Learning\n",
    "\n",
    "DO NOT MODIFY THIS FILE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bf1e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53da802",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from config import device\n",
    "import student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4584dfb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Using device: {}\"\n",
    "          \"\\n\".format(str(device)))\n",
    "\n",
    "    # Load the training dataset, and create a dataloader to generate a batch.\n",
    "    textField = data.Field(lower=True, include_lengths=True, batch_first=True,\n",
    "                           tokenize=student.tokenise,\n",
    "                           preprocessing=student.preprocessing,\n",
    "                           postprocessing=student.postprocessing,\n",
    "                           stop_words=student.stopWords)\n",
    "    labelField = data.Field(sequential=False, use_vocab=False, is_target=True)\n",
    "\n",
    "    dataset = data.TabularDataset('train.json', 'json',\n",
    "                                 {'reviewText': ('reviewText', textField),\n",
    "                                  'rating': ('rating', labelField),\n",
    "                                  'businessCategory': ('businessCategory', labelField)})\n",
    "\n",
    "    textField.build_vocab(dataset, vectors=student.wordVectors)\n",
    "\n",
    "    # Allow training on the entire dataset, or split it for training and validation.\n",
    "    if student.trainValSplit == 1:\n",
    "        trainLoader = data.BucketIterator(dataset, shuffle=True,\n",
    "                                          batch_size=student.batchSize,\n",
    "                                          sort_key=lambda x: len(x.reviewText),\n",
    "                                          sort_within_batch=True)\n",
    "    else:\n",
    "        train, validate = dataset.split(split_ratio=student.trainValSplit)\n",
    "\n",
    "        trainLoader, valLoader = data.BucketIterator.splits((train, validate),\n",
    "                                        shuffle=True, batch_size=student.batchSize,\n",
    "                                        sort_key=lambda x: len(x.reviewText),\n",
    "                                        sort_within_batch=True)\n",
    "\n",
    "    # Get model and optimiser from student.\n",
    "    net = student.net.to(device)\n",
    "    lossFunc = student.lossFunc\n",
    "    optimiser = student.optimiser\n",
    "\n",
    "    # Train.\n",
    "    for epoch in range(student.epochs):\n",
    "        runningLoss = 0\n",
    "\n",
    "        for i, batch in enumerate(trainLoader):\n",
    "            # Get a batch and potentially send it to GPU memory.\n",
    "            inputs = textField.vocab.vectors[batch.reviewText[0]].to(device)\n",
    "            length = batch.reviewText[1].to(device)\n",
    "            rating = batch.rating.to(device)\n",
    "            businessCategory = batch.businessCategory.to(device)\n",
    "\n",
    "            # PyTorch calculates gradients by accumulating contributions to them\n",
    "            # (useful for RNNs).  Hence we must manually set them to zero before\n",
    "            # calculating them.\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            # Forward pass through the network.\n",
    "            ratingOutput, categoryOutput = net(inputs, length)\n",
    "            loss = lossFunc(ratingOutput, categoryOutput, rating, businessCategory)\n",
    "\n",
    "            # Calculate gradients.\n",
    "            loss.backward()\n",
    "\n",
    "            # Minimise the loss according to the gradient.\n",
    "            optimiser.step()\n",
    "\n",
    "            runningLoss += loss.item()\n",
    "\n",
    "            if i % 32 == 31:\n",
    "                print(\"Epoch: %2d, Batch: %4d, Loss: %.3f\"\n",
    "                      % (epoch + 1, i + 1, runningLoss / 32))\n",
    "                runningLoss = 0\n",
    "\n",
    "    # Save model.\n",
    "    torch.save(net.state_dict(), 'savedModel.pth')\n",
    "    print(\"\\n\"\n",
    "          \"Model saved to savedModel.pth\")\n",
    "\n",
    "    # Test on validation data if it exists.\n",
    "    if student.trainValSplit != 1:\n",
    "        net.eval()\n",
    "\n",
    "        correctRatingOnlySum = 0\n",
    "        correctCategoryOnlySum = 0\n",
    "        bothCorrectSum = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in valLoader:\n",
    "                # Get a batch and potentially send it to GPU memory.\n",
    "                inputs = textField.vocab.vectors[batch.reviewText[0]].to(device)\n",
    "                length = batch.reviewText[1].to(device)\n",
    "                rating = batch.rating.to(device)\n",
    "                businessCategory = batch.businessCategory.to(device)\n",
    "\n",
    "                # Convert network output to integer values.\n",
    "                ratingOutputs, categoryOutputs = student.convertNetOutput(*net(inputs, length))\n",
    "\n",
    "                # Calculate performance\n",
    "                correctRating = rating == ratingOutputs.flatten()\n",
    "                correctCategory = businessCategory == categoryOutputs.flatten()\n",
    "\n",
    "                correctRatingOnlySum += torch.sum(correctRating & ~correctCategory).item()\n",
    "                correctCategoryOnlySum += torch.sum(correctCategory & ~correctRating).item()\n",
    "                bothCorrectSum += torch.sum(correctRating & correctCategory).item()\n",
    "\n",
    "        correctRatingOnlyPercent = correctRatingOnlySum / len(validate)\n",
    "        correctCategoryOnlyPercent = correctCategoryOnlySum / len(validate)\n",
    "        bothCorrectPercent = bothCorrectSum / len(validate)\n",
    "        neitherCorrectPer = 1 - correctRatingOnlyPercent \\\n",
    "                              - correctCategoryOnlyPercent \\\n",
    "                              - bothCorrectPercent\n",
    "\n",
    "        score = 100 * (bothCorrectPercent\n",
    "                       + 0.5 * correctCategoryOnlyPercent\n",
    "                       + 0.1 * correctRatingOnlyPercent)\n",
    "\n",
    "        print(\"\\n\"\n",
    "              \"Rating incorrect, business category incorrect: {:.2%}\\n\"\n",
    "              \"Rating correct, business category incorrect: {:.2%}\\n\"\n",
    "              \"Rating incorrect, business category correct: {:.2%}\\n\"\n",
    "              \"Rating correct, business category correct: {:.2%}\\n\"\n",
    "              \"\\n\"\n",
    "              \"Weighted score: {:.2f}\".format(neitherCorrectPer,\n",
    "                                              correctRatingOnlyPercent,\n",
    "                                              correctCategoryOnlyPercent,\n",
    "                                              bothCorrectPercent, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb2e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "formats": "ipynb,py",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
