{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c490f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77da2acd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "###\n",
    "#student.py\n",
    "\n",
    "#UNSW ZZEN9444 Neural Networks and Deep Learning\n",
    "\n",
    "#You may modify this file however you wish, including creating additional\n",
    "#variables, functions, classes, etc., so long as your code runs with the\n",
    "#a3main.py file unmodified, and you are only using the approved packages.\n",
    "\n",
    "#You have been given some default values for the variables stopWords,\n",
    "#wordVectors, trainValSplit, batchSize, epochs, and optimiser, as well as\n",
    "#a basic tokenise function.  You are encouraged to modify these to improve\n",
    "#the performance of your model.\n",
    "\n",
    "#The variable device may be used to refer to the CPU/GPU being used by PyTorch.\n",
    "#You may change this variable in the config.py file.\n",
    "\n",
    "#You may only use GloVe 6B word vectors as found in the torchtext package.\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torch.optim as toptim\n",
    "from torchtext.vocab import GloVe\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import re\n",
    "import torch.nn.init as init\n",
    "\n",
    "from config import device\n",
    "from config import device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31867b2",
   "metadata": {
    "cell_marker": "################################################################################"
   },
   "source": [
    "#### The following determines the processing of input data (review text) ######\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2465d20",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def tokenise(sample):\n",
    "    \"\"\"\n",
    "    Called before any processing of the text has occurred.\n",
    "    \"\"\"\n",
    "\n",
    "    processed = sample.split()\n",
    "\n",
    "    return processed\n",
    "\n",
    "def clean_texts(text):\n",
    "    \"\"\"\n",
    "    Clean text of reviews.\n",
    "    \"\"\"\n",
    "    # remove html mark tags\n",
    "    text=re.sub(\"(<.*?>)\", \"\", text)\n",
    "    # remove newline\n",
    "    text = re.sub('\\n', '', text)\n",
    "    #remove non-ascii and digits\n",
    "    text=re.sub(\"(\\\\W|\\\\d)\", \" \", text)\n",
    "    #remove other characters\n",
    "    text = re.sub('[,.\";!?:\\(\\)-/$\\'%`=><“·^\\{\\}_&#»«\\[\\]~|@、´，]+', \"\", text)\n",
    "    #remove whitespace\n",
    "    text=text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "def preprocessing(sample):\n",
    "    \"\"\"\n",
    "    Called after tokenising but before numericalising.\n",
    "    \"\"\"\n",
    "    sample = [clean_texts(text) for text in sample]\n",
    "\n",
    "\n",
    "    return sample\n",
    "\n",
    "def postprocessing(batch, vocab):\n",
    "    \"\"\"\n",
    "    Called after numericalising but before vectorising.\n",
    "    \"\"\"\n",
    "\n",
    "    return batch\n",
    "\n",
    "stopWords = {}\n",
    "dimension =100\n",
    "wordVectors = GloVe(name='6B', dim=dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4612bb",
   "metadata": {
    "cell_marker": "################################################################################",
    "lines_to_next_cell": 0
   },
   "source": [
    "###### The following determines the processing of label data (ratings) ########\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a117af9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def convertNetOutput(ratingOutput, categoryOutput):\n",
    "    \"\"\"\n",
    "    Your model will be assessed on the predictions it makes, which must be in\n",
    "    the same format as the dataset ratings and business categories.  The\n",
    "    predictions must be of type LongTensor, taking the values 0 or 1 for the\n",
    "    rating, and 0, 1, 2, 3, or 4 for the business category.  If your network\n",
    "    outputs a different representation convert the output here.\n",
    "    \"\"\"\n",
    "    ratingOutput = torch.tensor([1 if x > 0.5 else 0 for x in ratingOutput]).to(device)\n",
    "\n",
    "    # apply softmax to ensure category prediction labels are in [0, 1] range\n",
    "    softmax = tnn.Softmax(dim=1)\n",
    "    categoryOutput = softmax(categoryOutput)\n",
    "\n",
    "    # predict label with the highest probability\n",
    "    categoryOutput = torch.argmax(categoryOutput, dim=1)\n",
    "    return ratingOutput, categoryOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e5a335",
   "metadata": {
    "cell_marker": "################################################################################"
   },
   "source": [
    "##################### The following determines the model ######################\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5c23f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(tnn.Module):\n",
    "    \"\"\"\n",
    "    Class for creating the neural network.  The input to your network will be a\n",
    "    batch of reviews (in word vector form).  As reviews will have different\n",
    "    numbers of words in them, padding has been added to the end of the reviews\n",
    "    so we can form a batch of reviews of equal length.  Your forward method\n",
    "    should return an output for both the rating and the business category.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(network, self).__init__()\n",
    "        # number of expected features in the input\n",
    "        self.input_size = dimension\n",
    "        # number of features in the hidden state h\n",
    "        self.hidden_size = 50\n",
    "        # number of recurrent layers\n",
    "        self.layers = 2\n",
    "        # ReLU activation function\n",
    "        self.relu = tnn.ReLU()\n",
    "        # sigmoid activation function\n",
    "        self.sigmoid = tnn.Sigmoid()\n",
    "        # dropout layer - 30%\n",
    "        self.dropout = tnn.Dropout(0.3)\n",
    "\n",
    "        # define a multi-layer bidirectional LSTM RNN to an input sequence\n",
    "        self.lstm = tnn.LSTM(input_size=self.input_size,\n",
    "                             hidden_size=self.hidden_size,\n",
    "                             num_layers=self.layers,\n",
    "                             batch_first=True,\n",
    "                             bidirectional=True,\n",
    "                             dropout=0.2)\n",
    "\n",
    "        # initial fully connected hidden linear layer - * 2 for bidirectional\n",
    "        self.hidden_layer = tnn.Linear(self.hidden_size * 2, 100)\n",
    "\n",
    "        # fully connected output linear layer for ratings - 0,1 class\n",
    "        self.fc1 = tnn.Linear(100, 1)\n",
    "\n",
    "        # fully connected output linear layer for category - 0,1,2,3,4 class\n",
    "        self.fc2 = tnn.Linear(100, 5)\n",
    "\n",
    "    def forward(self, input, length):\n",
    "        # set initial states\n",
    "        self.h = torch.zeros(self.layers * 2, input.size(0), self.hidden_size).to(device)\n",
    "        self.c = torch.zeros(self.layers * 2, input.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # kaiming weight initialization\n",
    "        self.h = init.kaiming_normal_(self.h, mode='fan_out', nonlinearity='relu').to(device)\n",
    "        self.c = init.kaiming_normal_(self.c, mode='fan_out', nonlinearity='relu').to(device)\n",
    "\n",
    "        # pack a Tensor containing padded sequences of varying lengths,\n",
    "        # improves computational efficiency\n",
    "        if torch.cuda.is_available():\n",
    "            embedded_packed = tnn.utils.rnn.pack_padded_sequence(input.cpu(), length.cpu(), batch_first=True).to(device)\n",
    "        else:\n",
    "            embedded_packed = tnn.utils.rnn.pack_padded_sequence(input, length, batch_first=True)\n",
    "\n",
    "            # pass packed sequence through LSTM\n",
    "        lstm_out, (self.h, self.c) = self.lstm(embedded_packed)\n",
    "\n",
    "        # hidden state output\n",
    "        output = torch.cat((self.h[-2, :, :], self.h[-1, :, :]), dim=1)\n",
    "\n",
    "        # propagate through initial hidden layer\n",
    "        output = self.hidden_layer(output)\n",
    "        # apply ReLU activation\n",
    "        output = self.relu(output)\n",
    "        # apply dropout\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        # rating output - binary classification\n",
    "        rating_out = self.fc1(output)\n",
    "        rating_out = self.sigmoid(rating_out)\n",
    "\n",
    "        # category output - multiclass classification\n",
    "        category_out = self.fc2(output)\n",
    "\n",
    "        return rating_out, category_out\n",
    "        #pass\n",
    "\n",
    "class loss(tnn.Module):\n",
    "    \"\"\"\n",
    "    Class for creating the loss function.  The labels and outputs from your\n",
    "    network will be passed to the forward method during training.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(loss, self).__init__()\n",
    "        # binary cross entropy loss function for ratingOutput\n",
    "        self.binary_loss = tnn.BCELoss()\n",
    "\n",
    "        # cross entropy loss function for categoryOutput\n",
    "        self.cross_ent = tnn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, ratingOutput, categoryOutput, ratingTarget, categoryTarget):\n",
    "        # ratingOutput is of float type; convert ratingTarget to float\n",
    "        ratingTarget = ratingTarget.type(torch.FloatTensor).to(device)\n",
    "        # remove all the dimensions of size 1\n",
    "        ratingOutput = torch.squeeze(ratingOutput)\n",
    "\n",
    "        # apply rating loss function\n",
    "        rating_loss = self.binary_loss(ratingOutput, ratingTarget)\n",
    "\n",
    "        # apply category loss function\n",
    "        category_loss = self.cross_ent(categoryOutput, categoryTarget)\n",
    "\n",
    "        # compute total loss\n",
    "        total_loss = rating_loss + category_loss\n",
    "\n",
    "        return total_loss\n",
    "    #pass\n",
    "\n",
    "net = network()\n",
    "lossFunc = loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d1f26d",
   "metadata": {
    "cell_marker": "################################################################################"
   },
   "source": [
    "################# The following determines training options ###################\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f543eb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainValSplit = 0.8\n",
    "batchSize = 32\n",
    "epochs = 10\n",
    "optimiser = toptim.SGD(net.parameters(), lr=0.01)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "formats": "ipynb,py",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
